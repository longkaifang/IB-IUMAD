#### ðŸŒŸ This paper has been accepted to CVPR 2026.ðŸŒŸ
#

<h1 align="center">Towards an Incremental Unified Multimodal Anomaly Detection: Augmenting Multimodal Denoising From an Information Bottleneck Perspective</h1>
<h3 align="center">Kaifang Long<sup>1</sup>, Lianbo Ma<sup>1</sup>, Jiaqi Liu<sup>3</sup>, Liming Liu<sup>1</sup>, Guoyang Xie<sup>2</sup>, </h3>
<h3 align="center"><sup>1</sup>Northeastern University, <sup>2</sup>CATL, <sup>3</sup>UBC </h3>

# Abstract
The quest for incremental unified multimodal anomaly detection seeks to empower a single model with the ability to systematically detect anomalies across all categories and support incremental learning to accommodate emerging objects/categories. Central to this pursuit is resolving the catastrophic forgetting dilemma, which involves acquiring new knowledge while preserving prior learned knowledge. Despite some efforts to address this dilemma, a key oversight persists: ignoring the potential impact of spurious and redundant features on catastrophic forgetting. In this paper, we delve into the negative effect of spurious and redundant features on this dilemma in incremental unified frameworks, and reveal that under similar conditions, the multimodal framework developed by naive aggregation of unimodal architectures is more prone to forgetting. To address this issue, we introduce a novel denoising framework called IB-IUMAD, which exploits the complementary benefits of the Mamba decoder and information bottleneck fusion module:  the former dedicated to disentangle inter-object feature coupling, preventing spurious feature interference between objects; the latter serves to filter out redundant features from the fused features, thus explicitly preserving discriminative information. A series of theoretical analyses and experiments on MVTec 3D-AD and Eyecandies datasets demonstrates the effectiveness and competitive performance of IB-IUMAD. Code will be released.
